---
title: "R Notebook"
output: github_document
---
Tutoriel de référence : https://benjjneb.github.io/dada2/tutorial.html

```{bash, eval=FALSE}
#telechargement des donnees
wget https://github.com/ANF-MetaBioDiv/course-material/archive/refs/heads/main.zip
#deziper le fichier 
unzip main.zip
```

package :: fonction (dans le package here, on utilise la fonction here)
```{r}
refdb_folder <- here::here("data", "refdb")
refdb_folder
```

(créer des sous dossier), permettre de ne pas remplacer un dossier deja existant avec le meme nom
```{r}
if (!dir.exists(refdb_folder)) dir.create(refdb_folder, recursive = TRUE)
```

script = que des lignes de codes et commentaire
Rnotebook = zone réservé au code, affiche les résultats, commentaire
markdown = interpreter par github 

```{bash}
cp -R course-material-main/data/raw ./data
```



timeout = permet de prolonger le temps de chargement de rstudio (si connection lente)
```{r}
getOption("timeout")
options(timeout=1200)

# we save in variable the path to the refdb
# in the working space
silva_train_set <- file.path(refdb_folder,"silva_nr99_v138.1_train_set.fa.gz")

silva_species_assignment <- file.path(refdb_folder,"silva_species_assignment_v138.1.fa.gz")

# then we download the files if they don't already exist

if (!file.exists(silva_train_set)) {
  download.file("https://zenodo.org/record/4587955/files/silva_nr99_v138.1_train_set.fa.gz",silva_train_set,quiet = TRUE)
}

if (!file.exists(silva_species_assignment)) {
  download.file("https://zenodo.org/record/4587955/files/silva_species_assignment_v138.1.fa.gz",silva_species_assignment,quiet = TRUE)
}
```

Chercher tous les scripts d'un dossier R et sa documentation
```{r}
devtools::load_all(path="/home/rstudio/Adm2023_tutoriel/course-material-main/R")
```


Enregister le chemin d'accès au répertoire contenant nos donnees dans une variable 
```{r}
path_to_fastqs <- here::here("data", "raw")
```

Nous listons les fichiers transférés à l'aide de la fonction list.files(). L'argument pattern vous donne la possibilité de sélectionner uniquement les noms de fichiers correspondant à une expression régulière. Dans notre cas, nous sélectionnons tous les noms de fichiers se terminant par _R1.fastq.gz.
fnFs =definie une nouvelle variable, pointe vers la liste des donnees, va les chercher et recuperer tous les fichiers contenant "..."
```{r}
fnFs <- sort(list.files(path_to_fastqs,
                        pattern = "_R1.fastq.gz",
                        full.names = TRUE))
```

Nous faisons de même pour les échantillons inversés.
```{r}
fnRs <- sort(list.files(path_to_fastqs,
                        pattern = "_R2.fastq.gz",
                        full.names = TRUE))
```

basename(): supprimez le chemin pour conserver uniquement le nom du fichier.
strsplit(): diviser la chaîne de caractères selon un modèle défini. ?strsplitpour les documents.

```{r}
sample_names <- basename(fnFs) |>
  strsplit(split = "_") |>
  sapply(head, 1)
```


```{r}
basename(fnFs) |>
  head()
```

Il ne reste plus qu'à extraire le premier élément de chaque fichier.
```{r}
basename(fnFs) |>
  strsplit(split = "_") |>
  head()
```

```{r}
basename(fnFs) |>
  strsplit(split = "_") |>
  sapply(head, 1) |>
  head()
```

Astuce : vous pouvez obtenir la même chose en utilisant des expressions régulières :
```{r}
gsub("^.+/|_.+$", "", fnFs) |> head()
```


```{r}
# create a directory for the outputs
quality_folder <- here::here("outputs",
                             "dada2",
                             "quality_plots")

if (!dir.exists(quality_folder)) {
  dir.create(quality_folder, recursive = TRUE)
}

qualityprofile(fnFs,fnRs,file.path(quality_folder, "quality_plots.pd f"))
```

Creer un dossier pour les lectures des résultats 
```{r}
path_to_trimmed_reads <- here::here(
  "outputs",
  "dada2",
  "trimmed"
)

if (!dir.exists(path_to_trimmed_reads)) dir.create(path_to_trimmed_reads, recursive = TRUE)
```

Met les amorces dans une variable 
```{r}
primer_fwd  <- "CCTACGGGNBGCASCAG"
primer_rev  <- "GACTACNVGGGTATCTAAT"
```

fnFs = forewar (brin R1), fnRs = Reverse (brin R2)
```{r}
Biostrings::readDNAStringSet(
  fnFs[1],
  format = "fastq",
  nrec = 10
)
```


```{r}
Biostrings::readDNAStringSet(
  fnRs[1],
  format = "fastq",
  nrec = 10
)
```

```{bash}
pwd
cp -R /home/rstudio/Adm2023_tutoriel/course-material-main/bash .
```


```{r}
(primer_log <- primer_trim(
  forward_files = fnFs,
  reverse_files = fnRs,
  primer_fwd = primer_fwd,
  primer_rev = primer_rev,
  output_dir = path_to_trimmed_reads,
  min_size = 200
))
```

```{r}
nopFw <- sort(list.files(path_to_trimmed_reads, pattern = "R1", full.names = TRUE))
nopRv <- sort(list.files(path_to_trimmed_reads, pattern = "R2", full.names = TRUE))
```

Création d'un dossier
```{r}
path_to_filtered_reads <- here::here("outputs", "dada2", "filtered")
if (!dir.exists(path_to_filtered_reads)) dir.create(path_to_filtered_reads, recursive = TRUE)
```

Lister les chemins pour accéder au donnees
```{r}
filtFs <- file.path(path_to_filtered_reads, basename(fnFs))
filtRs <- file.path(path_to_filtered_reads, basename(fnRs))
```

Lien entre fichier et echantillons (vecteur)
```{r}
names(filtFs) <- sample_names
names(filtRs) <- sample_names
```

```{r}
(out <- dada2::filterAndTrim(
  fwd = nopFw,
  filt = filtFs,
  rev = nopRv,
  filt.rev = filtRs,
  minLen = 150,
  matchIDs = TRUE,
  maxN = 0,
  maxEE = c(3, 3),
  truncQ = 2
))
```

Debruiter données = modèle d'erreur 
```{r}
errF <- dada2::learnErrors(filtFs,
                           randomize = TRUE,
                           multithread = TRUE)
```

```{r}
errR <- dada2::learnErrors(filtRs,
                           randomize = TRUE,
                           multithread = TRUE)
```

visualisation du modèle d'erreur 
```{r}
dada2::plotErrors(errF, nominalQ=TRUE)
```

```{r}
library(gitcreds)
#mdp = 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
gitcreds_set()
```


```{r}
derepFs <- dada2::derepFastq(filtFs, verbose = TRUE)

derepRs <- dada2::derepFastq(filtRs, verbose = TRUE)
```

```{r}
dadaFs <- dada2::dada(derepFs, err = errF, multithread = TRUE)
```

```{r}
dadaRs <- dada2::dada(derepRs, err = errR, multithread = TRUE)
```

```{r}
mergers <- dada2::mergePairs(
  dadaF = dadaFs,
  derepF = derepFs,
  dadaR = dadaRs,
  derepR = derepRs,
  maxMismatch = 0,
  verbose = TRUE
)
```


```{r}
seqtab <- dada2::makeSequenceTable(mergers)
```

```{r}
seqtab_nochim <- dada2::removeBimeraDenovo(seqtab,
                                           method = "consensus",
                                           multithread = TRUE,
                                           verbose = TRUE)
```

```{r}
taxonomy <- dada2::assignTaxonomy(
  seqs = seqtab_nochim,
  refFasta = silva_train_set,
  taxLevels = c("Kingdom", "Phylum", "Class",
                "Order", "Family", "Genus",
                "Species"),
  multithread = TRUE,
  minBoot = 60
)
```


```{r}
taxonomy <- dada2::addSpecies(
  taxonomy,
  silva_species_assignment,
  allowMultiple = FALSE
)
```


```{r}
export_folder <- here::here("outputs", "dada2", "asv_table")

if (!dir.exists(export_folder)) dir.create(export_folder, recursive = TRUE)

saveRDS(object = seqtab_nochim,
        file = file.path(export_folder, "seqtab_nochim.rds"))

saveRDS(object = taxonomy,
        file = file.path(export_folder, "taxonomy.rds"))
```

```{r}
asv_seq <- colnames(seqtab_nochim)
```

```{r}
ndigits <- nchar(length(asv_seq))
asv_id <- sprintf(paste0("ASV_%0", ndigits, "d"), seq_along(asv_seq))
```

```{r}
row.names(taxonomy) <- colnames(seqtab_nochim) <- names(asv_seq) <- asv_id
```

```{r}
taxonomy_export <- df_export(taxonomy, new_rn = "asv")

seqtab_nochim_export <- t(seqtab_nochim)
seqtab_nochim_export <- df_export(seqtab_nochim_export, new_rn = "asv")
```

```{r}
write.table(taxonomy_export,
            file = file.path(export_folder, "taxonomy.tsv"),
            quote = FALSE,
            sep = "\t",
            row.names = FALSE)
```

```{r}
write.table(seqtab_nochim_export,
            file = file.path(export_folder, "asv_table.tsv"),
            quote = FALSE,
            sep = "\t",
            row.names = FALSE)
```

```{r}
cat(paste0(">", names(asv_seq), "\n", asv_seq),
    sep = "\n",
    file = file.path(export_folder, "asv.fasta"))
```

```{r}
getN <- function(x) sum(dada2::getUniques(x))

log_table <- data.frame(
  input = primer_log$in_reads,
  with_fwd_primer = primer_log$`w/adapters`,
  with_rev_primer = primer_log$`w/adapters2` ,
  with_both_primers = out[, 1],
  filtered = out[, 2],
  denoisedF = sapply(dadaFs, getN),
  denoisedR = sapply(dadaRs, getN),
  merged = sapply(mergers, getN),
  nonchim = rowSums(seqtab_nochim),
  perc_retained = rowSums(seqtab_nochim) / out[, 1] * 100
)

rownames(log_table) <- sample_names
```

```{r}
df_export(log_table, new_rn = "sample") |>
  write.table(file = file.path(export_folder, "log_table.tsv"),
              quote = FALSE,
              sep = "\t",
              row.names = FALSE)
```


